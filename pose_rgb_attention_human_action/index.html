<html>
<head>
  <title>Pose-conditioned Spatio-Temporal Attention for Human Action Recognition - INSA Lyon</title>
  <meta name="google-site-verification" content="NksNPfO4SApMtvU2rGHxr4DPan2Uy6Pz-rP9cA0k1mg"/>
  <script type="text/javascript" src="jquery.js"></script>
  <script type="text/javascript" src="jquery.mlens-1.0.min.js"></script>
  <style>
body
{
    font-family : Arial;
	background-color : #f2f2f2;
    font-size : 16px;
}
hr {
    display: block;
    height: 1px;
    border: 0;
    border-top: 1px solid #ccc;
    margin: 1em 0;
    padding: 0;
}
/* Everything but the jumbotron gets side spacing for mobile first views */
.header,
.row,
.footer {
  padding-left: 15px;
  padding-right: 15px;
}
.content
{
    width : 800px;
    padding : 25px 25px;
    margin : 5px auto;
    background-color : #fff;
    border-radius: 20px;
}
.content-title {
    width : 800px;
    background-color : inherit;
    margin-bottom : 0;
    padding-bottom : 0;
}

a, a:visited
{
    color : blue;
}

#authors
{
    text-align : center;
}

#conference
{
    text-align : center;
    font-style : italic;
}

#authors span
{
    margin : 0 10px;
    display : inline-block;
}

h1
{
    text-align : center;
    font-family : Arial;
    font-size : 35px;
}
h2 {
    font-family : Arial;
    font-size : 30px;
    padding : 0; margin : 10px;
}
h3 {
    font-family : Arial;
    font-size : 20px;
    padding : 0; margin : 10px;
}

p {
    line-height : 130%;
    margin : 10px;
}
li {
    margin : 10px 0;
}

.samples {
    float : left;
    width : 50%;
    text-align : center;
}
.cond {
    float : left;
    margin : 0 40px;
}
.cond-container {
    width : 700px;
    margin : 0 auto;
    text-align : center;
}














  </style>
</head>

<body>

<div class="content">
  <div class="content-title">
    <h1>Pose-conditioned Spatio-Temporal Attention<br>for Human Action Recognition</h1>
    <br>
  </div>

  <p id="authors">
      <span><a href="https://fabienbaradel.github.io"><img id="image" src="../images/bio-photo.jpg"
                                                           height="100"></img><br>Fabien Baradel</a><br>INSA Lyon</span>
    <span><a href="http://liris.cnrs.fr/christian.wolf/"><img id="image" src="../images/cwolf.jpg"
                                                              height="100"></img><br>Christian Wolf</a><br>INSA Lyon</span>
    <span><a href="http://liris.cnrs.fr/julien.mille/"><img id="image" src="../images/jmille.jpg"
                                                            height="100"></img><br>Julien Mille</a><br>INSA Centre Val de Loire</span><br
    clear="both">
    <br>
    <a href="https://arxiv.org/abs/1703.10106">arXiv:1703.10106</a>
  </p>

  <br>

  <h2>Abstract</h2>

  <p>
    We address human action recognition from multi-modal video data involving articulated pose and RGB frames and
    propose a two-stream approach.
    The pose stream is processed with a convolutional model taking as input a 3D tensor holding data from a
    sub-sequence. A specific joint ordering, which respects the topology of the human body, ensures that different
    convolutional layers correspond to meaningful levels of abstraction.
    The raw RGB stream is handled by a spatio-temporal soft-attention mechanism conditioned on features from the pose
    network. An LSTM network receives input from a set of image locations at each instant.
    A trainable glimpse sensor extracts features on a set of predefined locations specified by the pose stream, namely
    the 4 hands of the two people involved in the activity.
    Appearance features give important cues on hand motion and on objects held in each hand. We show that it is of
    high
    interest to shift the attention to different hands at different time steps depending on the activity
    itself.Finally
    a temporal attention mechanism learns how to fuse LSTM features over time. We evaluate the method on 3 datasets.
    State-of-the-art results are achieved on the largest dataset for human activity recognition, namely NTU-RGB+D, as
    well as on the SBU Kinect Interaction dataset. Performance close to state-of-the-art is achieved on the smaller MSR
    Daily Activity 3D
    dataset.
  </p>


  <center>
    <a href="https://arxiv.org/pdf/1703.10106.pdf">
      <strong>Download Paper</strong>
    </a>
  </center>
  <br>
</div>

<hr/>

<div class="content">
  <h2>Explainer Video</h2>
  <p>Below is a 4 minutes video briefly explaining our model and showing selected examples.</p>
  <div style='text-align:center;'>
    <iframe width="700" height="500" src="https://www.youtube.com/embed/kGLGgH_VAZw" frameborder="0"
            allowfullscreen></iframe>

  </div>
</div>

<hr/>


<div class="content">
  <h2>Visualisation of the Attention Process</h2>
  We show some selected actions and their corresponding representations according to our proposed model.

  <div class="content" style="text-align:center;">
    <h3>NTU RGB+D Dataset </h3>
    <div class="samples">
      <h4>RGB raw data</h4>
      <img src='gif/cropActionRGB_ntu.gif' width="90%">
    </div>
    <div class="samples">
      <h4>Attention process</h4>
      <img src='gif/attention_ntu.gif' width="90%">
    </div>
  </div>
  <div style="text-align:center;">
    <p><i> "Giving something to other person"</i></p>
  </div>
  <br clear="both">

  <hr/>

  <div class="content" style="text-align:center;">
    <h3>MSR Daily Activity 3D Dataset</h3>
    <div class="samples">
      <h4>RGB raw data</h4>
      <img src='gif/cropActionRGB_msr.gif' width="90%">
    </div>
    <div class="samples">
      <h4>Attention process</h4>
      <img src='gif/attention_msr.gif' width="90%">
    </div>
  </div>
  <div style="text-align:center;">
    <p><i> "Cellphone calling"</i></p>
  </div>
  <br clear="both">

  <hr/>

  <div class="content" style="text-align:center;">
    <h3>SBU Kinect Interaction Dataset </h3>
    <div class="samples">
      <h4>RGB raw data</h4>
      <img src='gif/cropActionRGB_sbu.gif' width="90%">
    </div>
    <div class="samples">
      <h4>Attention process</h4>
      <img src='gif/attention_sbu.gif' width="90%">
    </div>
  </div>
  <div style="text-align:center;">
    <p><i> "Giving something to other person"</i></p>
  </div>


</div>


<hr/>

<div class="content">
  <h2>Bibtex</h2>

  <pre><tt>@article{baradel2017a,
  author    = {Fabien Baradel and Christian Wolf and Julien Mille},
  title     = {Pose-conditioned Spatio-Temporal Attention for Human Action Recognition},
  journal   = {arxiv},
  volume    = {1703.10106},
  year      = {2017},
}</tt></pre>



</div>

<hr/>


<div class="content">
  <h2>Acknowledgements</h2>

  <p>
    This work was supported by the <a href="http://liris.cnrs.fr/deepvis/wiki/doku.php?id=start#publications">ANR/NSREC
    DeepVision project</a>
  </p>

</div>


</body>
</html>